{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "#                      x    y\n",
    "actions = {\"droite\" : (+1 , 0),\n",
    "           \"gauche\" : (-1 , 0),\n",
    "           \"bas\"    : ( 0 , -1),\n",
    "           \"haut\"   : ( 0 , +1)}\n",
    "\n",
    "class environnement:\n",
    "    def __init__(self):\n",
    "        self.x_max = 4\n",
    "        self.x_min = 0\n",
    "        self.y_max = 4\n",
    "        self.y_min = 0\n",
    "    def get_next_position(self, current_x,current_y, action :str):\n",
    "        # action = \"haut\" / \"bas\" ...\n",
    "        move_x = actions[action][0]\n",
    "        move_y = actions[action][1]\n",
    "        next_x = current_x + move_x\n",
    "        next_y = current_y + move_y\n",
    "        if next_x < self.x_min: next_x = self.x_min\n",
    "        if next_y < self.y_min: next_y = self.y_min\n",
    "        if next_x > self.x_max: next_x = self.x_max\n",
    "        if next_y > self.y_max: next_y = self.y_max\n",
    "        return next_x, next_y\n",
    "    \n",
    "    def get_reward(self, x, y):\n",
    "        pieges = [(0,1), (1,1), (2, 1)]\n",
    "        but    = [(2,2)]\n",
    "        if (x,y) in pieges : return -1\n",
    "        if (x,y) in but    : return 10\n",
    "        return 0\n",
    "        \n",
    "    def est_fini(self, x,y):\n",
    "        return self.get_reward(x,y) in [-1, 10]\n",
    "    \n",
    "    def get_etape(self, current_x, current_y, action):\n",
    "        next_x, next_y = self.get_next_position(current_x, current_y, action)\n",
    "        reward         = self.get_reward(next_x, next_y)\n",
    "        est_fini       = self.est_fini(next_x, next_y)\n",
    "        return (next_x, next_y, reward, est_fini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "class agent:\n",
    "    def __init__(self):\n",
    "        self.actions    = [\"droite\" , \"gauche\", \"bas\", \"haut\"]\n",
    "        self.q_function = {(x,y):{ \"droite\" : 0, \n",
    "                                   \"gauche\" : 0, \n",
    "                                   \"bas\"    : 0, \n",
    "                                   \"haut\"   : 0} for x in range(5) for y in range(5) }\n",
    "        self.current_x =0\n",
    "        self.current_y =0\n",
    "    def reset_position(self):\n",
    "        self.current_x =0\n",
    "        self.current_y =0\n",
    "    def get_action(self):\n",
    "        import random\n",
    "        return random.choice(self.actions)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_episode(env, agent):\n",
    "    episode = []\n",
    "    fini    = env.est_fini(agent.current_x, agent.current_y)\n",
    "    max_iter = 1000\n",
    "    \n",
    "    while not fini and max_iter>0:\n",
    "        current_x, current_y         = agent.current_x, agent.current_y\n",
    "        next_action                  = agent.get_action()\n",
    "        next_x, next_y, reward, fini = env.get_etape(agent.current_x, agent.current_y, next_action)\n",
    "        agent.current_x = next_x\n",
    "        agent.current_y = next_y\n",
    "        episode.append({  \"current_x\"   : current_x, \n",
    "                          \"current_y\"   : current_y, \n",
    "                          \"next_action\" : next_action, \n",
    "                          \"reward\"      : reward, \n",
    "                          \"fini\"        : fini })\n",
    "        max_iter -=1\n",
    "    return episode\n",
    "        \n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "a           = agent()\n",
    "env         = environnement()\n",
    "rewards = []\n",
    "for Nieme_episode in range(200000):\n",
    "    a.reset_position()\n",
    "    episode     = create_episode(env, a)\n",
    "    last_reward = episode[-1][\"reward\"]\n",
    "    episode, last_reward\n",
    "    for  dico in episode:\n",
    "        x      = dico[\"current_x\"  ]\n",
    "        y      = dico[\"current_y\"  ]\n",
    "        action = dico[\"next_action\"]\n",
    "        a.q_function[(x,y)][action] += last_reward \n",
    "    rewards.append(last_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0, 0): {'droite': -74648,\n",
       "  'gauche': -100271,\n",
       "  'bas': -100485,\n",
       "  'haut': -124244},\n",
       " (0, 1): {'droite': 0, 'gauche': 0, 'bas': 0, 'haut': 0},\n",
       " (0, 2): {'droite': 935, 'gauche': 608, 'bas': -237, 'haut': 963},\n",
       " (0, 3): {'droite': 2764, 'gauche': 2230, 'bas': 1252, 'haut': 2255},\n",
       " (0, 4): {'droite': 3389, 'gauche': 2885, 'bas': 2616, 'haut': 2699},\n",
       " (1, 0): {'droite': -465, 'gauche': -38514, 'bas': -29098, 'haut': -47698},\n",
       " (1, 1): {'droite': 0, 'gauche': 0, 'bas': 0, 'haut': 0},\n",
       " (1, 2): {'droite': 2100, 'gauche': 409, 'bas': -202, 'haut': 1075},\n",
       " (1, 3): {'droite': 4089, 'gauche': 2692, 'bas': 2447, 'haut': 3256},\n",
       " (1, 4): {'droite': 5025, 'gauche': 3750, 'bas': 3826, 'haut': 3693},\n",
       " (2, 0): {'droite': 30315, 'gauche': -12029, 'bas': -111, 'haut': -19437},\n",
       " (2, 1): {'droite': 0, 'gauche': 0, 'bas': 0, 'haut': 0},\n",
       " (2, 2): {'droite': 0, 'gauche': 0, 'bas': 0, 'haut': 0},\n",
       " (2, 3): {'droite': 5517, 'gauche': 4819, 'bas': 9420, 'haut': 5562},\n",
       " (2, 4): {'droite': 6999, 'gauche': 5956, 'bas': 8237, 'haut': 6867},\n",
       " (3, 0): {'droite': 25051, 'gauche': -686, 'bas': 18153, 'haut': 26219},\n",
       " (3, 1): {'droite': 14859, 'gauche': -4580, 'bas': 7619, 'haut': 26732},\n",
       " (3, 2): {'droite': 12234, 'gauche': 24500, 'bas': 5638, 'haut': 15227},\n",
       " (3, 3): {'droite': 10534, 'gauche': 12992, 'bas': 11123, 'haut': 11606},\n",
       " (3, 4): {'droite': 9910, 'gauche': 10605, 'bas': 10392, 'haut': 10722},\n",
       " (4, 0): {'droite': 17268, 'gauche': 12650, 'bas': 18628, 'haut': 24427},\n",
       " (4, 1): {'droite': 16782, 'gauche': 12773, 'bas': 12026, 'haut': 25718},\n",
       " (4, 2): {'droite': 17134, 'gauche': 19744, 'bas': 11231, 'haut': 18425},\n",
       " (4, 3): {'droite': 14108, 'gauche': 15119, 'bas': 11448, 'haut': 14593},\n",
       " (4, 4): {'droite': 12483, 'gauche': 12302, 'bas': 12201, 'haut': 11601}}"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.q_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_policy(q_function):\n",
    "    policy = {}\n",
    "    for x_y in q_function.keys():\n",
    "        dico        = q_function[x_y]\n",
    "        (action, _) = sorted([(k, dico[k]) for k in dico.keys()], key=lambda tuple_: tuple_[1])[-1]\n",
    "        policy[x_y] = action\n",
    "    return policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = get_policy(a.q_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 2 gauche\treward =  10\n"
     ]
    }
   ],
   "source": [
    "positions = []\n",
    "x_alea, y_alea = random.randint(0, 4), random.randint(0, 4)\n",
    "\n",
    "a.current_x = x_alea\n",
    "a.current_y = y_alea\n",
    "\n",
    "while not env.est_fini(a.current_x, a.current_y):\n",
    "    je_joue                  = policy [(a.current_x, a.current_y)]\n",
    "    print(a.current_x, a.current_y, je_joue, end=\"\\t\")\n",
    "    a.current_x, a.current_y = env.get_next_position(a.current_x, a.current_y, je_joue)\n",
    "    reward                   = env.get_reward(a.current_x, a.current_y)\n",
    "    print(\"reward = \",  reward )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.current_x, a.current_y = env.get_next_position(a.current_x, a.current_y, je_joue)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "cmap = plt.get_cmap('viridis')\n",
    "names = [\"droite\", \"gauche\", \"bas\", \"haut\"]\n",
    "colors = cmap(np.linspace(0, 1, len(names)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pi         = pd.DataFrame.from_dict(policy , orient=\"index\").reset_index()\n",
    "df_pi.columns = [\"position\", \"action\"]\n",
    "\n",
    "df_pi[\"x\"] = df_pi.position.map(lambda x : x[0])\n",
    "df_pi[\"y\"] = df_pi.position.map(lambda x : x[1])\n",
    "colors = {\"droite\": \"green\", \"haut\":\"blue\", \"gauche\":\"cyan\", \"bas\":\"yellow\"}\n",
    "colors = {\"droite\": 1, \"haut\":2, \"gauche\":3, \"bas\":4}\n",
    "\n",
    "df_pi.action = df_pi.action.map(colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot = df_pi.pivot_table(index=\"y\", columns=\"x\", values=\"action\", )\n",
    "pivot = pivot.sort_index(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a1da8d908>"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.heatmap(pivot, cmap=[\"green\", \"red\", \"blue\", \"cyan\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0, 0): 'droite',\n",
       " (0, 1): 'haut',\n",
       " (0, 2): 'haut',\n",
       " (0, 3): 'droite',\n",
       " (0, 4): 'droite',\n",
       " (1, 0): 'droite',\n",
       " (1, 1): 'haut',\n",
       " (1, 2): 'droite',\n",
       " (1, 3): 'droite',\n",
       " (1, 4): 'droite',\n",
       " (2, 0): 'droite',\n",
       " (2, 1): 'haut',\n",
       " (2, 2): 'haut',\n",
       " (2, 3): 'bas',\n",
       " (2, 4): 'bas',\n",
       " (3, 0): 'haut',\n",
       " (3, 1): 'haut',\n",
       " (3, 2): 'gauche',\n",
       " (3, 3): 'gauche',\n",
       " (3, 4): 'haut',\n",
       " (4, 0): 'haut',\n",
       " (4, 1): 'haut',\n",
       " (4, 2): 'gauche',\n",
       " (4, 3): 'gauche',\n",
       " (4, 4): 'droite'}"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
